from flask import Flask, render_template, Response
import cv2
from ultralytics import YOLO
import sys

# --- CONDITIONAL CAMERA SETUP ---
USE_PICAMERA = False
try:
    # Attempt to import Picamera2 for Raspberry Pi
    from picamera2 import Picamera2
    USE_PICAMERA = True
    print("INFO: Using Picamera2 (Raspberry Pi Camera) for capture.")
except ImportError:
    print("WARNING: Picamera2 not found. Falling back to OpenCV video capture (USB Webcam/CSI via V4L2).")


tw = Flask(__name__)

# Load the YOLOv5 model. Using 'yolov5s.pt' which is suitable for RPi's CPU.
# Use model.fuse() for slightly faster CPU inference.
model = YOLO("yolov5s.pt")
model.fuse()

# (COCO names)
traffic_classes = ['car', 'bus', 'truck', 'motorcycle', 'traffic light', 'stop sign']

# Initialize camera source
if USE_PICAMERA:
    picam = Picamera2()
    # Configure for 640x480 resolution in BGR format (compatible with OpenCV)
    config = picam.create_video_configuration(main={"size": (640, 480), "format": "BGR888"})
    picam.configure(config)
    picam.start()
    camera_source = picam
else:
    # webcam-thingy to capture
    cap = cv2.VideoCapture(0)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    camera_source = cap

def get_frame():
    """Reads a frame from the appropriate camera source."""
    if USE_PICAMERA:
        # picamera2 returns a numpy array directly
        return camera_source.capture_array()
    else:
        # cv2.VideoCapture returns success status and frame
        success, frame = camera_source.read()
        return frame if success else None

def gen_frames():
    """Generates the motion JPEG stream."""
    while True:
        frame = get_frame()
        if frame is None:
            # Skip if frame reading failed (e.g., end of stream or camera error)
            continue

        # Inference
        # Note: If you want to force CPU usage, you can pass device='cpu'
        results = model(frame, verbose=False)

        # Ensure the results list is not empty before proceeding
        if results and hasattr(results[0], 'boxes') and results[0].boxes.cls.numel() > 0:
            # Extract detected class labels
            labels = [model.names[int(cls)] for cls in results[0].boxes.cls]
            # Check if any detected label is a traffic class
            is_traffic = any(label in traffic_classes for label in labels)
        else:
            is_traffic = False

        # Status Label Logic (Kept exactly as requested)
        label_text = "Traffic Detected" if is_traffic else "No Traffic"
        color = (0, 255, 0) if is_traffic else (0, 0, 255)
        cv2.putText(frame, label_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)

        # Draw bounding boxes (Kept exactly as requested)
        if results and hasattr(results[0], 'boxes'):
            for box, cls_id in zip(results[0].boxes.xyxy, results[0].boxes.cls):
                x1, y1, x2, y2 = map(int, box)
                cls_name = model.names[int(cls_id)]
                cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 255, 0), 2)
                cv2.putText(frame, cls_name, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)

        # encode frame
        _, buffer = cv2.imencode('.jpg', frame)
        frame_bytes = buffer.tobytes()

        # Yield the stream part
        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')

# send the frame 2 flask
@app.route('/')
def index():
    return render_template('index.html')

@app.route('/video_feed')
def video_feed():
    return Response(gen_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')

# Define the WSGI application callable
application = tw

# If run directly (for development/testing), use Flask's built-in server
# NOTE: For production, use Gunicorn or similar WSGI server.
if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000, debug=True)
