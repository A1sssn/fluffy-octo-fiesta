from flask import Flask, render_template, Response
import cv2
from ultralytics import YOLO
import os

app = Flask(__name__)

# Load the YOLOv5 model
model = YOLO("yolov5s.pt")

# (COCO names)
traffic_classes = ['car', 'bus', 'truck', 'motorcycle', 'traffic light', 'stop sign']

# Initialize cap as a global variable, but don't open the camera here.
cap = None

def get_video_stream():
    """
    Initializes and returns the VideoCapture object.
    This function is called only when the app is running in the main process.
    """
    global cap
    if cap is None:
        cap = cv2.VideoCapture(0, cv2.CAP_V4L2)  # Use V4L2 backend for Raspberry Pi

        #  Force Logitech C310 into 720p MJPG mode (more reliable on RPi)
        cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*'MJPG'))
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)

        if not cap.isOpened():
            print("Error: Could not open camera.")
            cap = None
            return None
    return cap

@app.route('/')
def index():
    """Video streaming home page."""
    return render_template('index.html')

def gen_frames():
    """Video streaming generator function."""
    global cap
    camera = get_video_stream()
    if camera is None:
        print("Camera not available. Stopping frame generation.")
        return

    while True:
        success, frame = camera.read()
        if not success:
            print("Failed to read frame from camera. Reinitializing...")
            camera.release()
            cap = None  # reset global camera
            camera = get_video_stream()
            continue

        #  YOLO inference
        results = model(frame, verbose=False)

        #  Safety: handle no detections
        if not results or len(results) == 0 or results[0].boxes is None:
            labels = []
        else:
            labels = [model.names[int(cls)] for cls in results[0].boxes.cls]

        #  Traffic detection flag
        is_traffic = any(label in traffic_classes for label in labels)
        label_text = "Traffic Detected" if is_traffic else "No Traffic"
        color = (0, 255, 0) if is_traffic else (0, 0, 255)
        cv2.putText(frame, label_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)

        #  Draw bounding boxes only if detections exist
        if results and len(results) > 0 and results[0].boxes is not None:
            for box, cls_id in zip(results[0].boxes.xyxy, results[0].boxes.cls):
                x1, y1, x2, y2 = map(int, box)
                cls_name = model.names[int(cls_id)]
                cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 255, 0), 2)
                cv2.putText(frame, cls_name, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)

        #  Encode frame to JPEG
        ret, buffer = cv2.imencode('.jpg', frame)
        if not ret:
            print("Failed to encode frame.")
            break

        frame_bytes = buffer.tobytes()
        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')

@app.route('/video_feed')
def video_feed():
    """Route for the video stream."""
    return Response(gen_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')

if __name__ == '__main__':
    # Initialize the camera only if running in the main process.
    # The os.environ.get('WERKZEUG_RUN_MAIN') check prevents the camera from
    # being opened twice when Flask is in debug mode with auto-reloading.
    if os.environ.get('WERKZEUG_RUN_MAIN') or not app.debug:
        get_video_stream()
    
    app.run(host='0.0.0.0', debug=True)
